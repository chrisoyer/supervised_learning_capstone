{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing and Predicting Dog Shelter Holding Lengths\n",
    "\n",
    "## Intro\n",
    "I am using data sets I obtained from Kaggle: [dog breeds parameters scraped from at dogtime.com](https://www.kaggle.com/hocop1/cat-and-dog-breeds-parameters) and the Austin Animal Center's [intake and outake records.](https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes/) . \n",
    "\n",
    "The Austin Animal Center data describes the animals that the shelter accepts (from various places) and the dates the animal enter and leave the shelter. The time in the shelter is an important metric: it directly affects the cost of keeping the animal, and the ideal would be to have animals adopted out in a timely manner. \n",
    "\n",
    "I will import several python modules, load the AAC data, and clean it. I will then load a dataset of dog breed descriptions, and replace the 'breed' features, which has hundreds of breeds listed, with the breed description variables from this second data set. This will allow the use of a very descriptive feature, without expanding it into hundreds of binary features. I will then eliminate any unhelpful features, and model the data with several machine learning models to try to estimate the time a dog will spend in the shelter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'purmutation_importance' from 'sklearn.inspection' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\inspection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dc79344a05c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpurmutation_importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'purmutation_importance' from 'sklearn.inspection' (c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\inspection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "#data processing \n",
    "import scipy.stats as stats\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from boruta import BorutaPy\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#model selection\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.inspection import purmutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will need to inspect a lot of data\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_rows', 100)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "### Split data\n",
    "I don't want test data to influence decision on feature quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelter_inout_wbreeds_df = pd.read_parquet(path='../data/clean/inout_wbreeds.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = shelter_inout_wbreeds_df.loc[:, (shelter_inout_wbreeds_df.columns[shelter_inout_wbreeds_df.dtypes != 'object'].values)]\\\n",
    "    .drop(columns='time_in_shelter_days')\n",
    "y = shelter_inout_wbreeds_df['time_in_shelter_days']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr_ = X.corr().abs()\n",
    "X_corr_filt = X_corr_[(X_corr_ > .75) & ~(X_corr_ == 1)]\n",
    "for i, row in X_corr_filt.iterrows():\n",
    "    if row.sum() > 0: \n",
    "        print(\"{} is correlated with: \".format(i), end = '') \n",
    "        for ind, col in row.iteritems():\n",
    "            if ~np.isnan(col):\n",
    "                print(\"{} at {}\".format(ind, col))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look features with high correlations to multiple features\n",
    "sns.set_style('darkgrid')\n",
    "fig = plt.figure(figsize=(17,13))\n",
    "ax = sns.heatmap(X.corr(), center=0, linewidths=.1)\n",
    "ax.set_ylim(len(X.corr())-0, 0)\n",
    "ax.set_title('Feature Correlations', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get closer look at features with potential correlation issues\n",
    "plt.figure(figsize=(10, 20))\n",
    "corr_closeup = X.corr().loc[:, X.corr().index.isin(['Shorthair', 'Trainability',\n",
    "                                                    'Good_For_Novice_Owners',\n",
    "                                                    'in_type_Owner_Surrender',\n",
    "                                                    'Tolerates_Hot_Weather'])]\n",
    "ax = sns.heatmap(annot=True, cbar=False,  data=corr_closeup)\n",
    "ax.set_ylim(len(corr_closeup), 5)\n",
    "plt.title(\"Correlations Close-Up\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could drop Shorthair but let's keep it until we do algorithmic feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at variable distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.distplot(y_train)\n",
    "plt.title('Distribution of Target Variable', fontsize=20)\n",
    "ax.set_ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response variable is a time until an event. The null hypothesis is that adoptions are completely at random, and can be modeled with an exponential distribution. I will test this by comparing the data to an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = qqplot(data=y_train, dist='expon', fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the left tail of the data not follow an exponential distribution but the right tail does: this provides some support to the idea that only earlier adoptions will be predicted by dog characteristics, but very long-term stays are a random process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(shelter_inout_wbreeds_df.time_in_shelter_days[shelter_inout_wbreeds_df.time_in_shelter_days >365])\n",
    "plt.title('Distribution of Target: Close-up on those >365 days', fontsize=20)\n",
    "ax.set_ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite skewed, and apparently some dogs remain in the shelter for over 4 years! I will eliminate any observations exceeding 1 year: this is a small subset that should probably be considered separately to look at the specific issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_drop_index = y<=365\n",
    "y = y[y_drop_index]\n",
    "X = X[y_drop_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply boxcox transform for linear models. Also could model as GLM with log link function\n",
    "shift = .1\n",
    "y_train_transform = pd.Series(y_train) + shift # put in series so can add to each element\n",
    "y_test_transform = pd.Series(y_test) + shift\n",
    "y_transform = pd.Series(y) + shift\n",
    "#bc transform\n",
    "y_train_transform, y_train_bc = boxcox(y_train_transform) \n",
    "y_test_transform = boxcox(y_test_transform, lmbda=y_train_bc) # use lambda from training data\n",
    "y_transform = boxcox(y_transform, lmbda=y_train_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to store data used to do boxcox transform so it can be reversed later\n",
    "def reverse_bc(y, lambda_used=y_train_bc, shift=shift):\n",
    "    x = inv_boxcox(y, lmbda=lambda_used)\n",
    "    x -= shift\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.distplot(y_train_transform)\n",
    "plt.title(\"Transformed y\", fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a normal distribution but much improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot feature distributions\n",
    "X.hist(layout=(-1,5), figsize=(14,20));    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Feature Selection\n",
    "To narrow down the features I will perform a Boruta feature elimination to find a set of features to test various models on; Boruta compares a randomized pseudo version of the features to real features, and selects only those features which prove beneficial to the model. I need an initial model to use as a parameter in the Boruta algorithm, and will do a random search to find a satisfactory model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define search parameters and perform random search to find best params\n",
    "rforest_params = {'criterion': ('mse', 'mae'),\n",
    "                 'max_features': ('log2', 'sqrt', .2, .15),  \n",
    "                 'max_depth': (5, 15, 30),\n",
    "                 'min_samples_split': (10, 20, 30)}  \n",
    "\n",
    "rforest = RandomForestRegressor(n_estimators=30, verbose=0, n_jobs=-1, \n",
    "                                oob_score=False, bootstrap=True)\n",
    "random_forest_best = RandomizedSearchCV(estimator=rforest, n_iter=20, \n",
    "                                        n_jobs=-1, \n",
    "                                        param_distributions=rforest_params, \n",
    "                                        cv=3)\n",
    "random_forest_best.fit(X_train, y_train_transform)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#best hypers\n",
    "random_forest_best = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
    "                      max_features='auto', max_leaf_nodes=None,\n",
    "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                      min_samples_leaf=1, min_samples_split=20,\n",
    "                      min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=-1,\n",
    "                      oob_score=False, random_state=None, verbose=0,\n",
    "                      warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use hypers from search in model\n",
    "random_forest_best_selector = RandomForestRegressor(**random_forest_best.best_params_).fit(X_train, y_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use Bourta feature elimination to get alternative list of features to use\n",
    "boruta_est_cnt = 30\n",
    "boruta_selector_more = BorutaPy(random_forest_best_selector, n_estimators=boruta_est_cnt, verbose=0, perc=50)\n",
    "boruta_selector_more.fit(X_train.values, y_train)  #Boruta only accepts np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_selector_fewer = BorutaPy(random_forest_best_selector, n_estimators=boruta_est_cnt, verbose=0, perc=100)\n",
    "boruta_selector_fewer.fit(X_train.values, y_train)  #Boruta only accepts np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of features Selected by Bourta Alg: More: {}, fewer: {}\"\\\n",
    "      .format(boruta_selector_more.n_features_, boruta_selector_fewer.n_features_))\n",
    "print(\"Selected Features (More): {}\".format(X_train.columns[boruta_selector_more.support_]))\n",
    "print(\"Selected Features (Fewer): {}\".format(X_train.columns[boruta_selector_fewer.support_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new X with reducted feature set\n",
    "X_train_red = X_train.loc[:,X_train.columns[boruta_selector_more.support_]]\n",
    "X_test_red = X_test.loc[:,X_test.columns[boruta_selector_more.support_]]\n",
    "X_red = X.loc[:,X.columns[boruta_selector_more.support_]]\n",
    "X_train_red_fewer = X_train.loc[:,X_train.columns[boruta_selector_fewer.support_]]\n",
    "X_test_red_fewer = X_test.loc[:,X_test.columns[boruta_selector_fewer.support_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_best_fewer = clone(random_forest_best_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare scores for different levels of retained features\n",
    "rf_cv_score_more_features = cross_val_score(estimator=random_forest_best_selector,\n",
    "                                            X=X_train_red, y=y_train_transform, \n",
    "                                            cv=3, n_jobs=-1)\n",
    "rf_cv_score_fewer_features = cross_val_score(estimator=random_forest_best_fewer, \n",
    "                                             X=X_train_red_fewer, y=y_train_transform, \n",
    "                                             cv=3, n_jobs=-1)\n",
    "print(\"Score with More features retained: {}\".format(rf_cv_score_more_features))\n",
    "print(\"Score with fewer features retained: {}\".format(rf_cv_score_fewer_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are almost the same when using the highly reduced features set. However, the number of features selected is not completely stable (the runs with perc=100 have varied from 0 to 8 features selected), so I have erred on the side of caution and used the results from perc=50 as my X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review feature importance of selected features\n",
    "random_forest_best_selector.fit(X_train_red, y_train_transform)\n",
    "reduced_features = X_train_red.columns.to_list()\n",
    "important_features = pd.DataFrame(data=random_forest_best_selector.feature_importances_,\n",
    "                                  index=reduced_features)\n",
    "important_features.columns = ['importance']\n",
    "important_features.sort_values(by='importance', ascending=False, inplace=True)\n",
    "figimp = plt.figure(figsize=(10, 6))\n",
    "aximp = sns.barplot(y=important_features.index,\n",
    "                    x=important_features['importance'], orient='h')\n",
    "aximp.set(title='Ranked Featured Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Importance\n",
    "permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "We will first try a linear regression since that has the advantage of speed, and explainability if it works well.  \n",
    "We will use a random search to find the best hyperparameters.  \n",
    "Models with regularization needs standardized data. Since most data is from OHE, we will use minmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_red_stand =  MinMaxScaler(feature_range=(0,1)).fit_transform(X_train_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'alpha': stats.uniform(.0001, 100),\n",
    "         'l1_ratio': stats.uniform(.1, .9)}\n",
    "enet = ElasticNet()\n",
    "enet_rsearch = RandomizedSearchCV(estimator=enet, param_distributions=params, \n",
    "                                  n_iter=12, cv=3)\n",
    "nested_lr_scores = cross_validate(estimator=enet_rsearch, X=X_train_red_stand, \n",
    "                                  y=y_train_transform, cv=3, n_jobs=-1, \n",
    "                               return_estimator=True)\n",
    "print('Test scores are: {}'.format(nested_lr_scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Tree Models\n",
    "There may be a number of interactions, so forest-based models may be useful to improve predictive ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define search space and set up model\n",
    "rforest_params = {'criterion': ('mse', 'mae'),\n",
    "                 'max_features': ('log2', 'sqrt', .2, .15),  \n",
    "                 'max_depth': (5, 15, 30),\n",
    "                 'min_samples_split': (10, 20, 30)}  \n",
    "\n",
    "rforest = RandomForestRegressor(n_estimators=60, verbose=0, n_jobs=-1,\n",
    "                                oob_score=False, bootstrap=True)\n",
    "rforest_rsearch = RandomizedSearchCV(estimator=rforest,\n",
    "                                     param_distributions=rforest_params,\n",
    "                                     n_iter=60, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validate model\n",
    "rf_cv_scores = cross_validate(estimator=rforest_rsearch, X=X_train_red,\n",
    "                              y=y_train_transform, n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_params = {'loss': ('ls', 'lad', 'huber'),\n",
    "                 'subsample': (.5, .8, 1),\n",
    "                 'learning_rate': (.05, .08, .1, .2, .3, .6),\n",
    "                 'max_depth': (2, 3, 5, 6)}\n",
    "grad_boost = GradientBoostingRegressor(n_estimators=60)\n",
    "grad_boost_rs = RandomizedSearchCV(estimator=grad_boost,\n",
    "                                   param_distributions=gboost_params, cv=3)\n",
    "gboost_cv_score = cross_val_score(estimator=grad_boost_rs, X=X_train_red, \n",
    "                                  y=y_train_transform, n_jobs=-1, cv=3, \n",
    "                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Models - KNN and SVM\n",
    "Since these models are still not explaining the majority of the variance, let's try some other models. We will do a similar nested CV search to get cross-validated scores of the best parameter set as determinted by the random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_params = {'n_neighbors': (3, 5, 7),\n",
    "             'weights': ('uniform', 'distance'),\n",
    "             'p': (1.5, 2, 2.5)}\n",
    "knr = KNeighborsRegressor()\n",
    "knr_rsear = RandomizedSearchCV(\n",
    "    estimator=knr, param_distributions=kn_params, n_jobs=-1, n_iter=12, cv=3)\n",
    "knr_cv_score = cross_val_score(\n",
    "    estimator=grad_boost, X=X_train_red_stand, y=y_train_transform, n_jobs=-1, \n",
    "    cv=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_params = {'C': (.4, .7, 1, 1.3, 2, 10),\n",
    "              'epsilon': (.001, .01, .1),\n",
    "              'kernel': ('linear', 'poly', 'rbf')}\n",
    "svr = SVR()\n",
    "svr_search = RandomizedSearchCV(\n",
    "    estimator=svr, param_distributions=svr_params, n_jobs=-1, n_iter=12, cv=3)\n",
    "svr_cv_score = cross_val_score(\n",
    "    estimator=svr_search, X=X_train_red_stand, y=y_train_transform, n_jobs=-1, cv=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review the cross-validated scores for the tested models\n",
    "model_scores_df = pd.DataFrame(columns = [\"1st\", \"2nd\", \"3rd\"])\n",
    "model_scores_df.loc['Linear_Regression'] = nested_lr_scores['test_score']\n",
    "model_scores_df.loc['Random_Forest'] = rf_cv_scores['test_score']  \n",
    "model_scores_df.loc[\"GradientBoost_Forest\"] = gboost_cv_score\n",
    "model_scores_df.loc['KNR'] = knr_cv_score\n",
    "model_scores_df.loc[\"SVR\"] = svr_cv_score\n",
    "model_scores_df[\"mean\"] = model_scores_df.mean(axis=1)\n",
    "model_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the gradient boosted tree model as it had somewhat better scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the model that can be used for future predictions\n",
    "gboost_params = {'loss': ('ls', 'lad', 'huber'),\n",
    "                 'subsample': (.5, .8, 1),\n",
    "                 'learning_rate': (.05, .08, .1, .2, .3, .6),\n",
    "                 'max_depth': (2, 3, 5, 6)}\n",
    "grad_boost = GradientBoostingRegressor(n_estimators=60)\n",
    "model = RandomizedSearchCV(estimator=grad_boost, param_distributions=gboost_params, cv=3, refit=True)\n",
    "model.fit(X_train_red, y_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = GradientBoostingRegressor(**model.best_params_).fit(X_train_red, y_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the grandient-boosted forest model. The tree models were approximately equal in cross-validation scores.  The Nearest Neighbors model was able to add some predictive information, but less than the tree-bsed models.  \n",
    "The models are able to explain about 25% of the variance in the time spent in the shelter before the dogs leave. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "The model we used does not have easily interpretable coefficients. We can look more closely at the features that are most important.\n",
    "It was surprising to me that some features I anticipated being important were not amoung the highest features, such as Black - this is evidence against the existance of \"Black Dog Syndrome\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = pd.DataFrame(data=best_model.feature_importances_, index=X_red.columns.to_list())\n",
    "model_features.columns = ['importance']\n",
    "model_features.sort_values(by='importance', ascending=False, inplace=True)\n",
    "for feature, f_importance in model_features[0:5].iterrows():\n",
    "    plt.figure(feature)\n",
    "    sns.boxplot(x=X_red[feature], y=y_transform)\n",
    "    plt.ylabel('transformed y')\n",
    "    plt.title(\"{} vs time in shelter\".format(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the important variables seem too directly interpretable for on impact on the outcome variable, which makes sense given the way the models performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions in original units and compare to actual\n",
    "y_pred = inv_boxcox(model.predict(X_red), y_train_bc) \n",
    "y_pred -= shift\n",
    "plt.figure(figsize=(12,10))\n",
    "fig_resid = sns.scatterplot(x=y, y=y_pred, alpha=.2)\n",
    "plt.plot([0, 0], [365, 365], color='r' )\n",
    "plt.title(\"Predicted vs Actual with GBR\", fontsize=20)\n",
    "plt.xlabel('Actual', fontsize=15)\n",
    "plt.ylabel('Predicted', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Distribution of SVR model\n",
    "Let's see if the other models are getting a different set of observations right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr_model = RandomizedSearchCV(estimator=knr, param_distributions=kn_params, n_jobs=-1, n_iter=12, cv=3)\n",
    "knr_model.fit(X_train_red, y_train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knr = inv_boxcox(knr_model.predict(X_red), y_train_bc) \n",
    "y_pred_knr -= shift\n",
    "plt.figure(figsize=(12,10))\n",
    "fig_resid = sns.scatterplot(x=y, y=y_pred_knr, alpha=.2)\n",
    "plt.plot([0, 0], [365, 365], color='r' )\n",
    "plt.title(\"Predicted vs Actual with KNR model\", fontsize=20)\n",
    "plt.xlabel('Actual', fontsize=15)\n",
    "plt.ylabel('Predicted', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not picking up on some of the very-long staying dogs. It is capturing the cluster at around 40-75 days. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this project indicate that while the length of the stay in the shelter is influenced by some of the recorded factors, most of the variability is caused by other factors or is random. The most important factors are whether an animal is neutered while in the shelter, the age of the animal, and whether it is a stray.   \n",
    "\n",
    "### Further Study\n",
    "Additional avenues for research would include looking out the outcome categories (such as Adoption, Return to Owner, etc. ) as a predicted variable, or looking for additional variables that might influence the amount of time the animals stay in the shelter.  \n",
    "It may be that important characteristics of certain dogs is not being identified in the data collected and a focus on identifying these features would be beneficial for avoiding the very long stays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
